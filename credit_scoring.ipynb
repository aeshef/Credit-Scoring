{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import category_encoders as ce\n",
    "import scorecardpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и сохраняем их в датафрейм\n",
    "df = pd.read_csv(\"/Users/artemshevchenko/Downloads/Проект по скорингу 4/tr_for_students.csv\", sep=\",\")\n",
    "\n",
    "val = pd.read_csv(\"/Users/artemshevchenko/Downloads/Проект по скорингу 4/vl_for_students.csv\", sep=\",\")\n",
    "\n",
    "#  разделим наш тренировочный датасет на две части - в одном будут содержаться численные переменные, а в другом строковые переменные и прочие объекты\n",
    "continious = df.select_dtypes(include=['float', 'int'])\n",
    "categorical = df.select_dtypes(include=['object'])\n",
    "\n",
    "# будем всегда иметь под рукой расшифровку названий колонок, поскольку лазать за ними в эксель каждый раз очень неудобно\n",
    "col_desk = pd.read_excel(\"/Users/artemshevchenko/Downloads/Проект по скорингу 4/Columns description.xlsx\", usecols=[1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Размер тренировочной выборки:\")\n",
    "print(df.shape)\n",
    "print()\n",
    "print(\"Размер валидационной выборки:\")\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распределение непрерывных переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распределение категориальных переменных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу оговоримся, что так как пропущенные значения есть и в тренировочной, и валидационной выборке, заполнять мы будем их обе. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала почистим наш датафрейм от неинформативных признаков. Так, например, почти точно признаки issue_d, содержащий дату, а также признак addr_state, содержащий локацию заявителя, не информативны для датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('issue_d', axis=1, inplace=True)\n",
    "# df.drop('addr_state', axis=1, inplace=True)\n",
    "\n",
    "val.drop('issue_d', axis=1, inplace=True)\n",
    "# val.drop('addr_state', axis=1, inplace=True)\n",
    "\n",
    "# я хотел удалить признак addr_state, однако позже протестировал гипотезу, что с его помощью\n",
    "# модель работает точнее, так что он остался, а его обработка будет дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим subgrade на числа (рейтинг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Тренировочная выборка:\")\n",
    "print(*sorted(df[\"sub_grade\"].unique()))\n",
    "\n",
    "print()\n",
    "print(\"Валидационная выборка:\")\n",
    "print(*sorted(val[\"sub_grade\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "df['sub_grade'] = encoder.fit_transform(df['sub_grade'].values.reshape(-1, 1))\n",
    "\n",
    "# Преобразуйте тестовый датасет\n",
    "val['sub_grade'] = encoder.transform(val['sub_grade'].values.reshape(-1, 1))\n",
    "\n",
    "print(\"Для тренировочной выборки:\")\n",
    "print(\"Уникальных кредитных рейтингов\", len(df[\"sub_grade\"].unique()))\n",
    "print(\"Пропущенных значений\", df[\"sub_grade\"].isna().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Для валидационной выборки:\")\n",
    "print(\"Уникальных кредитных рейтингов\", len(val[\"sub_grade\"].unique()))\n",
    "print(\"Пропущенных значений\", val[\"sub_grade\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причины, почему клиенты обращаются за кредитом, достаточно содержательны, и мы оставим их для дальнейшего анализа (purpose). Для этого заменим их на фиктивные переменные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=[\"purpose\"])\n",
    "df = encoder.fit_transform(df)\n",
    "val = encoder.fit_transform(val)\n",
    "\n",
    "print(\"Для тренировочной выборки:\")\n",
    "print(\"Уникальных причин обращения\", len(df[\"purpose\"].unique()))\n",
    "print(\"Пропущенных значений\", df[\"purpose\"].isna().sum())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Для валидационной выборки:\")\n",
    "print(\"Уникальных причин обращения\", len(val[\"purpose\"].unique()))\n",
    "print(\"Пропущенных значений\", val[\"purpose\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на то, насколько часто кредит выдают в зависимости от статуса владения недвижимостью (home_ownership)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "df_target_temp = df[\"def\"]\n",
    "\n",
    "for ownership in df[\"home_ownership\"].unique():\n",
    "    result = df_target_temp[df[\"home_ownership\"] == ownership].sum()\n",
    "    results[ownership] = result\n",
    "\n",
    "# Выведите результаты\n",
    "for status in results:\n",
    "    print(f\"{status}: {results[status]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=[\"home_ownership\"])\n",
    "\n",
    "print(\"В тренировочной выборке\")\n",
    "df = encoder.fit_transform(df)\n",
    "print(*df[\"home_ownership\"].unique())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"В валидационной выборке\")\n",
    "val = encoder.fit_transform(val)\n",
    "print(*val[\"home_ownership\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и обещал, аналогичные действия проворачиваю для признака addr_state, означаюего state, который фигурирует в заявке на кредит клиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=[\"addr_state\"])\n",
    "\n",
    "print(\"В тренировочной выборке\")\n",
    "df = encoder.fit_transform(df)\n",
    "print(*df[\"addr_state\"].unique())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"В валидационной выборке\")\n",
    "val = encoder.fit_transform(val)\n",
    "print(*val[\"addr_state\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось рассмотреть признак emp_title. Тут мы уже немного затронем логику заполнения пропущенных значений в датасете, которой посвящена следующая часть проекта.\n",
    "\n",
    "emp_title, то есть бренд работодателя - нередко может хоть и грубо, но говорить о статусе и влиять на кредитоспособность клиента. Мы могли бы преобразовать категориальный признак emp_title в булевый, где мы бы хранили статус работоустроенности (ведь, очевидно, пропущенные значения в этом ключе почти точно говорят об отсутствии у заявителя работы на момент подачи), однако, исходя из выше сказанного, мы поступим иначе.\n",
    "Мы построим биекцию из различных названий работы в натуральные числа, а пропущенные значения заполним нулями. Так, мы и одновременно сохраним информативность признака по наличию работы у заявителя, и, возможно, проследим связь между решение о выдаче кредита разным заявителем, работающим в одном и том же месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим, сколько всего уникальных работодателей указано в датасет. В работе мы полагаем, что человеческий фактор в виде допущения ошибки при указании работы в анкете (APPLE и APLE), из-за чего названия будут зашифрованы в разные натуральные числа, незначителен и не повлияет на точность модели: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполним пропущенные значения при отсутствии работы нулём\n",
    "df[\"emp_title\"].fillna(0, inplace=True)\n",
    "val[\"emp_title\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"В тренировочной выборке:\")\n",
    "print(\"Всего заполненных полей про работу\", df[\"emp_title\"].shape[0])\n",
    "print(\"Уникальных работодателей в датасете\", df[\"emp_title\"].unique().shape[0])\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"В валидационной выборке:\")\n",
    "print(\"Всего заполненных полей про работу\", val[\"emp_title\"].shape[0])\n",
    "print(\"Уникальных работодателей в датасете\", val[\"emp_title\"].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так, видно, что ожидание большого количества совпадащих работодателей крайне мало, однако мы поступим так, как договорились:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=[\"emp_title\"])\n",
    "\n",
    "df = encoder.fit_transform(df)\n",
    "val = encoder.fit_transform(val)\n",
    "\n",
    "print(\"В тренировочной выборке:\")\n",
    "print(*df[\"emp_title\"].unique())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"В валидационной выборке:\")\n",
    "print(*val[\"emp_title\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь замёмся пропущенными значениями, а именно переменными типа NaN. Определим сколько их, в каких столбцах они содержатся, далее заполним их по определённой логике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поймём, сколько в нашем датафрейме переменных типа NaN\n",
    "pd.DataFrame(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(val.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим (по тренировочной выборке), есть ли в пропущенных значениях emp_length такие, которые мы могли бы предсказать по старому имеющемся набору пар (emp_title, emp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим, скольким людям из тех, чье значения переменной emp_length не указаны, одобряли кредит, а каким - нет\n",
    "print(\"Люди, чье значения переменной emp_length не указаны, но кому одобряли кредит:\")\n",
    "print(df_target_temp[df[\"emp_length\"].isna()].sum())\n",
    "\n",
    "# их всего 531 из 61147, так что этими значениями можно пренебречь. однако мы посмотрим, у кого из них указана должность, а у кого - нет\n",
    "# посмотрим, сколько тех, у кого указана должность, emp_length = 0, а df_target = 1\n",
    "\n",
    "needed_indexes = df_target_temp[(df[\"emp_length\"].isna()) & (df[\"emp_title\"] != 0)].index\n",
    "print()\n",
    "print(\"Люди, у которых указана должность, emp_length = 0, а df_target = 1\")\n",
    "print(df_target_temp[needed_indexes].sum())\n",
    "\n",
    "# имеем, что у 0 из 531 человек, у которых не указан emp_length, указана должность. поэтому мы можем смело заменить все NaN на 0\n",
    "# имеем, что у всех 531 человек, у которых emp_length не указан, есть название работы. тогда просто отбросить эти значения мы не можем, так что по-хорошему заполнить \n",
    "# их средний временем работы\n",
    "\n",
    "df[\"emp_length\"].fillna(df[\"emp_length\"].mean(), inplace=True)\n",
    "val[\"emp_length\"].fillna(val[\"emp_length\"].mean(), inplace=True)\n",
    "\n",
    "# проверим, что NaN значений больше нет\n",
    "print()\n",
    "print(\"Пропущенных значений в тренировочной выборке:\")\n",
    "print(df[\"emp_length\"].isna().sum())\n",
    "print()\n",
    "print(\"Пропущенных значений в валидационной выборке:\")\n",
    "print(val[\"emp_length\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберёмся с mths_since_recent_inq, num_accts_ever_120_pd, num_tl_90g_dpd_24m, acc_open_past_24mths, avg_cur_bal, tot_hi_cred_lim:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что mths_since_recent_inq (Месяцы с последнего запроса), m_accts_ever_120_pd (Количество счетов более 120 дней просроченных за всю историю), num_tl_90g_dpd_24m (Количество счетов с просрочкой более 90 дней за последние 24 месяца), avg_cur_bal (Средний текущий баланс по всем счетам), tot_hi_cred_lim (Общий кредитный лимит), acc_open_past_24mths (Количество открытых счетов за последние 24 месяца) - все имеют достаточно схожее количество пропущенных значений в переменных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(val.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом важно, что все эти признаки содержат в своих переменных нулевые значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_null(feature):\n",
    "    if (0, 0) != df[df[f\"{feature}\"] == 0].shape:\n",
    "        print(f\"{feature} contains null values\")\n",
    "    else:\n",
    "        print(f\"{feature} does not contain null values\")\n",
    "\n",
    "contains_null(\"mths_since_recent_inq\")\n",
    "contains_null(\"num_accts_ever_120_pd\")\n",
    "contains_null(\"num_tl_90g_dpd_24m\")\n",
    "contains_null(\"avg_cur_bal\")\n",
    "contains_null(\"tot_hi_cred_lim\")\n",
    "contains_null(\"acc_open_past_24mths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, заполнять данные значения нулями создаст потенциальную неточность ввиду достаточно большого количества пропущенных значений. С другой стороны, логическое преобразование признака в другой, более информативный, также представляется трудной задачей - \n",
    "\n",
    "Попробуем рассмотреть эти признаки по отдельности и совершим логические преобразования, разделив тех, у кого прежде просто не было счетов и тех, кто имел счет, но не делал по нему просрочек по выплатам, не создавал запросов на новые кредиты или имел нулевой кредитный лимит:\n",
    "\n",
    "Для примера, рассмотрим mths_since_recent_inq:\n",
    "\n",
    "$$\\begin{cases}\n",
    "    \\text{mthssincerecentinq[i] } = 0 \\text{ - запрашивал в течение последнего месяца} \\\\\n",
    "    \\text{mthssincerecentinq[i]  = NaN - не запрашивал вообще}\n",
    "\\end{cases}$$\n",
    "$$\\Downarrow $$\n",
    "$$\\begin{cases}\n",
    "    \\text{запрашивал когда-либо} \\Rightarrow \\text{mthssincerecentinq[i]  } += 1 \\\\\n",
    "    \\text{запрашивал в течение последнего месяца} \\Rightarrow \\text{mthssincerecentinq[i]  } = 1 \\\\\n",
    "    \\text{не запрашивал вообще} \\Rightarrow \\text{mthssincerecentinq[i]  } = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Воспользуемся той же логикой для заполнения пропущенных значений в выше указанных признаках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_numeric = lambda x: x + 1 if pd.notna(x) else 0\n",
    "\n",
    "for feature in [\"mths_since_recent_inq\", \"num_accts_ever_120_pd\", \"num_tl_90g_dpd_24m\", \"avg_cur_bal\", \"tot_hi_cred_lim\", \"acc_open_past_24mths\"]:\n",
    "    df[f\"{feature}\"] = df[f\"{feature}\"].apply(increase_numeric)\n",
    "    val[f\"{feature}\"] = val[f\"{feature}\"].apply(increase_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, остались ли пропущенные значения в столбцах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(val.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация новых признаков:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сгенерировать ряд новых признаков из имеющихся:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df[\"def\"]\n",
    "del df[\"def\"]\n",
    "\n",
    "val_target = val[\"def\"]\n",
    "del val[\"def\"]\n",
    "\n",
    "df_for_eda = pd.concat([df, val], ignore_index=True)\n",
    "\n",
    "print(\"Размер тренировочной выборки:\")\n",
    "print(df.shape)\n",
    "print()\n",
    "print(\"Размер валидационной выборки:\")\n",
    "print(val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = df_for_eda.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Вывод результатов\n",
    "if len(non_numeric_columns) == 0:\n",
    "    print(\"df_for_eda содержит только числа.\")\n",
    "else:\n",
    "    print(\"df_for_eda содержит нечисловые значения в следующих столбцах:\")\n",
    "    print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cor = px.imshow(df_for_eda.corr(), text_auto=True)\n",
    "fig_cor.update_layout(\n",
    "     title={\n",
    "        \"text\": \"Корреляция переменных\",\n",
    "        \"x\": 0.5\n",
    "    },\n",
    "\n",
    ")\n",
    "fig_cor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = df, df_target, val, val_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели линейной регрессии\n",
    "model = LinearRegression()\n",
    "\n",
    "# обучение модели\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# получение прогнозов\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# оценка качества модели\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# вывод результатов\n",
    "print(f\"Среднеквадратичная ошибка (MSE): {mse}\")\n",
    "print(f\"Коэффициент детерминации (R^2): {r2}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# получение коэффициентов регрессии\n",
    "coefficients = pd.DataFrame({'Признак': X_train.columns, 'Коэффициент': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "# создание массива с замененными значениями\n",
    "y_pred_new = np.where(y_pred < threshold, 0, 1)\n",
    "\n",
    "# посмотрим срез из 5 элементов в старом и новом массивах, а также на типы данных, содержащихся в них\n",
    "print(y_pred[:5])\n",
    "print(y_pred.dtype)\n",
    "print(\"\")\n",
    "print(y_pred_new[:5])\n",
    "print(y_pred_new.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_new)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fig_mis = px.imshow(cm, text_auto=True)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # доступные solver-ы для модели логистической регрессии в sklearn\n",
    "# solvers = ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga']\n",
    "# # возможные значения достаточного количество итераций для сходимости модели\n",
    "# max_iters = [10, 100, 500, 1000, 5000, 5100, 10000] \n",
    "\n",
    "# # некоторые переменные для удобства\n",
    "# best_accuracy = 0\n",
    "# best_solver = None\n",
    "# best_max_iter = None\n",
    "\n",
    "# # игнорируем предупреждения о недостаточном количестве итераций\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# for solver in solvers:\n",
    "#     for max_iter in max_iters:\n",
    "#         model = LogisticRegression(solver=solver, max_iter=max_iter)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#         if accuracy > best_accuracy:\n",
    "#             best_accuracy = accuracy    \n",
    "#             best_solver = solver\n",
    "#             best_max_iter = max_iter\n",
    "            \n",
    "# # восстанавливаем вывод предупреждений\n",
    "# warnings.filterwarnings(\"default\")\n",
    "\n",
    "# print(\"Лучший solver:\", best_solver)\n",
    "# print(\"Лучшее количество итераций (max_iter):\", best_max_iter)\n",
    "# print(\"Лучшая accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=5000)\n",
    "iterations = []\n",
    "accuracies = []\n",
    "\n",
    "max_iter_values = [10, 20, 30, 40, 50, 100, 200, 500, 1000]\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# обучение модели и запись точности\n",
    "for max_iter in max_iter_values:\n",
    "    model.max_iter = max_iter\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    iterations.append(max_iter)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, accuracies, marker='o')\n",
    "plt.title('Зависимость точности от количества итераций')\n",
    "plt.xlabel('Количество итераций')\n",
    "plt.ylabel('Точность')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели логистической регрессии\n",
    "model = LogisticRegression(solver = \"liblinear\", max_iter = 500)\n",
    "\n",
    "# обучение модели\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# получение прогнозов\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# оценка качества модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fig_mis = px.imshow(cm, text_auto=True)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score= {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('recall_score = {:.3f}'.format(recall_score(y_test, y_pred)))\n",
    "print('precision_score = {:.3f}'.format(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=2)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Model accuracy: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fig_mis = px.imshow(cm, text_auto=True)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy_score= {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('recall_score = {:.3f}'.format(recall_score(y_test, y_pred)))\n",
    "print('precision_score = {:.3f}'.format(precision_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs = model.predict_proba(X_train)[:, 1]\n",
    "lr_probs_val = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_roc = sc.perf_eva(y_train, lr_probs, plot_type=[\"roc\"], title=\"train\")\n",
    "val_roc = sc.perf_eva(y_test,lr_probs_val, plot_type=[\"roc\"], title=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты ROC-AUC получились не очень удовлетворительными, но я ещё не раз буду проводить работу над обработкой данных с соответвующими комментариями."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
